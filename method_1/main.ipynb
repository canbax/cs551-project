{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "# train1 is numerical data types\n",
    "trainY = df['SalePrice']\n",
    "df.drop(['SalePrice'], axis=1, inplace=True)\n",
    "train1 = df.select_dtypes(exclude=['object'])\n",
    "# train2 is categorical data types\n",
    "train2 = df.select_dtypes(['object'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.1808532430766737\n0.4281418889536744\n0.1846395473739006\n25.86350107192993 seconds passed\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import time\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "def get_train_data():\n",
    "    \"\"\" return numerical and categorical data respectively \"\"\"\n",
    "    df = pd.read_csv('data/train.csv')\n",
    "\n",
    "    y = df['SalePrice']\n",
    "    df.drop(['SalePrice', 'Id'], axis=1, inplace=True)\n",
    "    # x1 is numerical data types\n",
    "    x1 = df.select_dtypes(exclude=['object'])\n",
    "    # x2 is categorical data types\n",
    "    x2 = df.select_dtypes(['object'])\n",
    "\n",
    "    x1 = x1.to_numpy()\n",
    "    x2 = x2.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    # scale to [0,1] range\n",
    "    # x1 = MinMaxScaler(feature_range=(0, 1), copy=False).fit_transform(x1)\n",
    "        \n",
    "    # mean 0 variance 1\n",
    "    # x1 = StandardScaler(copy=False).fit_transform(x1)\n",
    "    \n",
    "    # x1 = RobustScaler().fit_transform(x1)\n",
    "    \n",
    "    # x1 = np.log(x1 + 1)\n",
    "\n",
    "    return x1, x2, y\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    \"\"\" return numerical and categorical data respectively \"\"\"\n",
    "    df = pd.read_csv('data/test.csv')\n",
    "\n",
    "    df.drop(['Id'], axis=1, inplace=True)\n",
    "    # train1 is numerical data types\n",
    "    x1 = df.select_dtypes(exclude=['object'])\n",
    "    # train2 is categorical data types\n",
    "    x2 = df.select_dtypes(['object'])\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "    scaler.fit_transform(x1)\n",
    "    \n",
    "    return x1.to_numpy(), x2.to_numpy()\n",
    "\n",
    "\n",
    "def get_bayes_model(x, y, bin_size: int):\n",
    "    \"\"\" counts the occurence of each label for each feature and for each value \"\"\"\n",
    "\n",
    "    m, n = x.shape\n",
    "    # for each feature, keep a dictionary for frequency of values\n",
    "    # model is an array of dictionary of dictionary which simply indexes feature index, feature value and label frequency\n",
    "    model = [{}] * n\n",
    "\n",
    "    for i in range(m):\n",
    "        label = round(y[i] / bin_size)\n",
    "        for j in range(n):\n",
    "            val = x[i][j]\n",
    "            if val in model[j]:\n",
    "                if label in model[j][val]:\n",
    "                    model[j][val][label] = model[j][val][label] + 1\n",
    "                else:\n",
    "                    model[j][val][label] = 1\n",
    "            else:\n",
    "                model[j][val] = {label: 1}\n",
    "\n",
    "    # normalize counts of labels to [0,1]\n",
    "    for feature in model:\n",
    "        for val in feature:\n",
    "            s = 0\n",
    "            for freq in feature[val]:\n",
    "                s = s + feature[val][freq]\n",
    "            for freq in feature[val]:\n",
    "                feature[val][freq] = feature[val][freq] / s\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_with_categorical(model, x, bin_size):\n",
    "    m, n = x.shape\n",
    "    y_ = np.zeros((m, 1), dtype=np.int32)\n",
    "    for i in range(m):\n",
    "        curr = x[i, :]\n",
    "        for j in range(n):\n",
    "            d = model[j][curr[j]]\n",
    "            # select the most frequent label as label\n",
    "            selected_label = max(d, key=lambda key: d[key])\n",
    "            y_[i] = y_[i] + selected_label\n",
    "        # find the average value\n",
    "        y_[i] = y_[i] / n\n",
    "    return y_ * bin_size\n",
    "\n",
    "\n",
    "def replace_nan2mean(x, col_mean=[]):\n",
    "    if len(col_mean) == 0:\n",
    "        col_mean = np.nanmean(x, axis=0)\n",
    "\n",
    "    # find indices where nan value is present\n",
    "    idxs = np.where(np.isnan(x))\n",
    "\n",
    "    # replace inds with avg of column\n",
    "    x[idxs] = np.take(col_mean, idxs[1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def predict_with_numerical(x, y, x_test):\n",
    "    x = replace_nan2mean(x)\n",
    "    x_test = replace_nan2mean(x_test, np.mean(x, axis=0))\n",
    "    clf = SVR(gamma='scale', kernel='linear')\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    return clf.predict(x_test)\n",
    "\n",
    "def predict():\n",
    "    x1, x2, y = get_train_data()\n",
    "    x1_test, x2_test = get_test_data()\n",
    "\n",
    "    t = time.time()\n",
    "    y_1 = predict_with_numerical(x1, y, x1)\n",
    "    \n",
    "    \n",
    "    bin_size = 1000\n",
    "    m = get_bayes_model(x2, y, bin_size)\n",
    "    y_2 = predict_with_categorical(m, x2, bin_size)\n",
    "\n",
    "    print(rmsle(y, y_1))\n",
    "    print(rmsle(y, y_2))\n",
    "    print(rmsle(y, y_1 * 0.8 + y_2 * 0.2))\n",
    "\n",
    "    # get_submission_file(y_1)\n",
    "    print(str(time.time() - t) + ' seconds passed')\n",
    "    return y_1, y_2\n",
    "    # return (y_1 + y_2) / 2\n",
    "\n",
    "\n",
    "def get_submission_file(y):\n",
    "    df = pd.DataFrame({'Id': range(1461, 2920), 'SalePrice': y})\n",
    "    df.to_csv('submit.csv', index=None)\n",
    "\n",
    "\n",
    "def rmsle(y, y_):\n",
    "    \"\"\" A function to calculate Root Mean Squared Logarithmic Error (RMSLE) \"\"\"\n",
    "    assert len(y) == len(y_)\n",
    "    return np.sqrt(np.mean((np.log(1 + y) - np.log(1 + y_))**2))\n",
    "\n",
    "\n",
    "y_1, y_2 = predict()\n",
    "\n",
    "# print(y_)\n",
    "# print(np.unique(y_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f740465d540b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.8\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-86196fb8741e>\u001b[0m in \u001b[0;36mrmsle\u001b[1;34m(y, y_)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;34m\"\"\" A function to calculate Root Mean Squared Logarithmic Error (RMSLE) \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "rmsle(y, y_1 * 0.8 + y_2 * 0.2)"
   ]
  }
 ]
}